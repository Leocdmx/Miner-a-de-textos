{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta='/Users/Leon/Documents/Data GH/Mineria de textos/corpusTASS-2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Cargar archivos\n",
    "df_train = pd.read_csv(os.path.join(ruta, 'train.tsv'), sep='\\t')\n",
    "df_test = pd.read_csv(os.path.join(ruta, 'test.tsv'), sep='\\t')\n",
    "df_dev = pd.read_csv(os.path.join(ruta, 'dev.tsv'), sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtrar columnas y eliminar filas con valores nulos\n",
    "df_train_filtered = df_train[['texto', 'etiqueta']].dropna()\n",
    "df_dev_filtered = df_dev[['texto', 'etiqueta']].dropna()\n",
    "df_test_filtered = df_test[['texto', 'etiqueta']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Haremos la limpieza de los textos con expresiones regulares\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    texto = re.sub(r'@\\w+', '', texto)  # eliminar menciones\n",
    "    texto = re.sub(r'http\\S+|www\\S+', '', texto)  # eliminar URLs\n",
    "    texto = re.sub(r'#\\w+', '', texto)  # eliminar hashtags\n",
    "    #texto = re.sub(r'[^\\w\\sáéíóúüÁÉÍÓÚÜ]', '', texto)  # eliminar acentos y caracteres especiales\n",
    "    texto = texto.lower()  # convertir a minúsculas\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()  # eliminar espacios extra\n",
    "    texto = texto.encode('ascii', 'ignore').decode('ascii')  # eliminar emojis y simbolos no ASCII\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_filtered['texto'] = df_train_filtered['texto'].astype(str).apply(limpiar_texto)\n",
    "df_dev_filtered['texto'] = df_dev_filtered['texto'].astype(str).apply(limpiar_texto)\n",
    "df_test_filtered['texto'] = df_test_filtered['texto'].astype(str).apply(limpiar_texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "#convertimos a formato dataset\n",
    "dataset_train = Dataset.from_pandas(df_train_filtered.reset_index(drop=True))\n",
    "dataset_dev = Dataset.from_pandas(df_dev_filtered.reset_index(drop=True))\n",
    "dataset_test = Dataset.from_pandas(df_test_filtered.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4802/4802 [02:52<00:00, 27.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'texto': 'jajajaja eso es verdad aqu no hay uno cuerdo', 'etiqueta': 'N', 'prediccion_modelo': 'neg'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Usa un modelo en español compatible con análisis de sentimiento desde Hugging Face\n",
    "classifier = pipeline(\"text-classification\", model=\"finiteautomata/beto-sentiment-analysis\")\n",
    "\n",
    "# Aplica el modelo a los textos del corpus para predecir el sentimiento.\n",
    "def clasificar_sentimiento(ejemplo):\n",
    "    resultado = classifier(ejemplo['texto'])\n",
    "    return {'prediccion_modelo': resultado[0]['label'].lower()}  # minúscula para facilitar comparación\n",
    "\n",
    "# Probamos\n",
    "dataset_train = dataset_train.map(clasificar_sentimiento)\n",
    "#dataset_dev = dataset_dev.map(clasificar_sentimiento)\n",
    "#dataset_test = dataset_test.map(clasificar_sentimiento)\n",
    "\n",
    "# Mostramos\n",
    "print(dataset_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texto': 'mi ltima partida jugada con sona support la grandes razones para jugar sona',\n",
       " 'etiqueta': 'P',\n",
       " 'prediccion_modelo': 'pos'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuadramos etiquetas y predicciones\n",
    "mapa_etiquetas = {'P': 'pos', 'NEU': 'neu', 'N': 'neg'}\n",
    "y_true = [mapa_etiquetas[e] for e in dataset_train['etiqueta']]\n",
    "y_pred = dataset_train['prediccion_modelo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg neg\n",
      "neu neu\n",
      "neu neu\n",
      "pos pos\n",
      "pos neu\n",
      "pos pos\n",
      "neg neg\n",
      "neu neu\n",
      "pos pos\n",
      "pos pos\n",
      "neg neg\n",
      "neu neu\n",
      "neg neg\n",
      "neu neu\n",
      "pos pos\n",
      "pos pos\n",
      "neu neu\n",
      "neg neg\n",
      "neu neu\n",
      "neu neu\n",
      "neg neg\n",
      "pos pos\n",
      "neu neu\n",
      "neg neu\n",
      "neu neu\n",
      "neg neg\n",
      "neu neu\n",
      "neg neg\n",
      "pos pos\n",
      "pos neu\n",
      "neg neg\n",
      "pos pos\n",
      "pos pos\n",
      "pos pos\n",
      "neg neg\n",
      "pos pos\n",
      "neu neu\n",
      "neg neg\n",
      "neg neg\n",
      "neg neg\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,40): print(y_true[i],y_pred[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.9379425239483549\n",
      "\n",
      " Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg      0.955     0.949     0.952      1885\n",
      "         neu      0.898     0.938     0.917      1523\n",
      "         pos      0.962     0.923     0.942      1394\n",
      "\n",
      "    accuracy                          0.938      4802\n",
      "   macro avg      0.938     0.937     0.937      4802\n",
      "weighted avg      0.939     0.938     0.938      4802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Exactitud:\", accuracy_score(y_true, y_pred))\n",
    "print(\"\\n Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "#  Matriz de confusión\n",
    "etiquetas = ['pos', 'neu', 'neg']\n",
    "cm = confusion_matrix(y_true, y_pred, labels=etiquetas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplos correctos:\n",
      "\n",
      "Texto: buen da pap te amo mucho\n",
      "Etiqueta real: pos | Predicción: pos\n",
      "\n",
      "Texto: me hacen quedar como un zorro lpm pero todas las minas que me nombran estn re buenas matense\n",
      "Etiqueta real: neg | Predicción: neg\n",
      "\n",
      "Texto: nos fue bien en el parcial solo nos faltan 4\n",
      "Etiqueta real: pos | Predicción: pos\n",
      "\n",
      " Ejemplos equivocados:\n",
      "\n",
      "Texto: a todas las personas que fueron el mejor respaldo este 2016 sobre todo a ti amor\n",
      "Etiqueta real: neu | Predicción: pos\n",
      "\n",
      "Texto: la verdad extrao mucho mi vida universitaria\n",
      "Etiqueta real: neg | Predicción: neu\n",
      "\n",
      "Texto: feliz cumpleaos julian z q dios te bendiga muchsimo un fuerte abrazo desde huacho\n",
      "Etiqueta real: neu | Predicción: pos\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Crear listas comparables\n",
    "etiquetas_reales = [mapa_etiquetas[e] for e in dataset_train['etiqueta']]\n",
    "predicciones = dataset_train['prediccion_modelo']\n",
    "textos = dataset_train['texto']\n",
    "\n",
    "# Buscar aciertos y errores\n",
    "aciertos = []\n",
    "errores = []\n",
    "\n",
    "for texto, real, pred in zip(textos, etiquetas_reales, predicciones):\n",
    "    if real == pred:\n",
    "        aciertos.append((texto, real, pred))\n",
    "    else:\n",
    "        errores.append((texto, real, pred))\n",
    "\n",
    "# Mostrar ejemplos aleatorios\n",
    "print(\"Ejemplos correctos:\")\n",
    "for texto, real, pred in random.sample(aciertos, min(3, len(aciertos))):\n",
    "    print(f\"\\nTexto: {texto}\\nEtiqueta real: {real} | Predicción: {pred}\")\n",
    "\n",
    "print(\"\\n Ejemplos equivocados:\")\n",
    "for texto, real, pred in random.sample(errores, min(3, len(errores))):\n",
    "    print(f\"\\nTexto: {texto}\\nEtiqueta real: {real} | Predicción: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Leon/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map:  24%|██▍       | 1143/4802 [00:48<02:17, 26.61 examples/s]"
     ]
    }
   ],
   "source": [
    " # Usa un modelo en español compatible con análisis de sentimiento desde Hugging Face\n",
    "classifier = pipeline(\"text-classification\", model=\"finiteautomata/beto-sentiment-analysis\")\n",
    "\n",
    "# Aplica el modelo a los textos del corpus para predecir el sentimiento.\n",
    "def clasificar_sentimiento(ejemplo):\n",
    "    resultado = classifier(ejemplo['texto'])\n",
    "    return {'prediccion_modelo': resultado[0]['label'].lower()}  # minúscula para facilitar comparación\n",
    "\n",
    "# Probamos\n",
    "dataset_train = dataset_train.map(clasificar_sentimiento)\n",
    "#dataset_dev = dataset_dev.map(clasificar_sentimiento)\n",
    "#dataset_test = dataset_test.map(clasificar_sentimiento)\n",
    "\n",
    "# Mostramos\n",
    "print(dataset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(\"Exactitud:\", accuracy_score(y_true, y_pred))\n",
    "print(\"\\n Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "#  Matriz de confusión\n",
    "etiquetas = ['pos', 'neu', 'neg']\n",
    "cm = confusion_matrix(y_true, y_pred, labels=etiquetas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear listas comparables\n",
    "etiquetas_reales = [mapa_etiquetas[e] for e in dataset_train['etiqueta']]\n",
    "predicciones = dataset_train['prediccion_modelo']\n",
    "textos = dataset_train['texto']\n",
    "\n",
    "# Buscar aciertos y errores\n",
    "aciertos = []\n",
    "errores = []\n",
    "\n",
    "for texto, real, pred in zip(textos, etiquetas_reales, predicciones):\n",
    "    if real == pred:\n",
    "        aciertos.append((texto, real, pred))\n",
    "    else:\n",
    "        errores.append((texto, real, pred))\n",
    "\n",
    "# Mostrar ejemplos aleatorios\n",
    "print(\"Ejemplos correctos:\")\n",
    "for texto, real, pred in random.sample(aciertos, min(3, len(aciertos))):\n",
    "    print(f\"\\nTexto: {texto}\\nEtiqueta real: {real} | Predicción: {pred}\")\n",
    "\n",
    "print(\"\\n Ejemplos equivocados:\")\n",
    "for texto, real, pred in random.sample(errores, min(3, len(errores))):\n",
    "    print(f\"\\nTexto: {texto}\\nEtiqueta real: {real} | Predicción: {pred}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
